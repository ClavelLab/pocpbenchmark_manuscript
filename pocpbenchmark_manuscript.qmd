---
title: Clearer, better, faster, reproducible bacterial genus delineation procedure
affiliations:
  - id: uka
    name: University Hospital of RWTH Aachen
    department: Institute of Medical Microbiology
    group: Functional Microbiome Research Group
    country: Germany
    url: https://ror.org/02gm5zw39
authors:
  - name: Charlie Pauvert
    corresponding: true
    orcid: 0000-0001-9832-2507
    email: cpauvert@ukaachen.de
    affiliations:
      - ref: uka
    roles:
      - Conceptualization
      - Formal analysis
      - Investigation
      - Software
      - Visualization
      - Writing - original draft
      - Writing - review & editing
  - name: Thomas C.A. Hitch
    orcid: 0000-0003-2244-7412
    affiliations:
      - ref: uka
    roles:
      - Conceptualization
      - Supervision
      - Visualization
      - Writing - review & editing
  - name: Thomas Clavel
    orcid: 0000-0002-7229-5595
    affiliations:
      - ref: uka
    roles:
      - Funding acquisition
      - Resources
      - Writing - review & editing
license: "CC BY"
bibliography: references.bib
crossref:
  custom:
    - kind: float
      key: suppfig
      latex-env: suppfig
      reference-prefix: Figure S
      space-before-numbering: false
      latex-list-of-description: Supplementary Figure
---

```{r setup}
library(tidyverse)
library(targets)
library(cowplot)
```


# Introduction

In the last three years only, the number of bacterial genomes in the RefSeq collection has increased by 35 000 yearly, both from isolates and metagenomes [@haftRefSeqProkaryoticGenome2024]. To analyse these genomes, we need clear and quick methods to taxonomically assign genomes.
For species, Average Nucleotide Identity [ANI, @jainHighThroughputANI2018] has been developed and shown to delineate species almost unanimously [@parksCompleteDomainspeciesTaxonomy2020].
However, ANI is unable to delineate genera [@qinProposedGenusBoundary2014].
While no single ANI threshold has been proposed for genus delineation, family-specific thresholds have been suggested using both the ANI value and alignment fraction, however the lack of a universal threshold limits their usability [@barcoGenusDefinitionBacteria2020].
An alternative to ANI is the Average Amino acid Identity (AAI) which uses protein sequences instead of genomic nucleic sequences [@konstantinidisGenomeBasedTaxonomyProkaryotes2005].
A genus delineation threshold was proposed based on AAI [@konstantinidisUncultivatedMicrobesNeed2017], but this approach is seldom applied [@dieckmannEDGAR3ComparativeGenomics2021; @kimIntroducingEzAAIPipeline2021; @medlarAAIprofilerFastProteomewide2018].
Another protein sequence-based genus delineation method was proposed with an interpretable metric: the Percentage of Conserved Proteins (POCP) [@qinProposedGenusBoundary2014].
If two bacterial entities share more than half of their conserved proteins, i.e., POCP > 50%, they belong to the same genus.

POCP is widely used within the community to assign novel bacterial taxa to known genera, or support the proposal of novel genera [@afrizalEnhancedCulturedDiversity2022; @chaplinHydrogeniiclostidiumMannosilyticumGen2020; @gonzalezAcidiferrimicrobiumAustraleGen2020; @hitchBroadDiversityHuman2024; @wylensekCollectionBacterialIsolates2020]
A major limitation of POCP is that the comparison of all proteins within each genome to each other is computationally demanding.
Given that the number of valid genus names has nearly doubled (@suppfig-lpsn) since the original proposition of POCP by @qinProposedGenusBoundary2014, scalable methods as well as a timely reevaluation of the POCP is required.


@hernandez-salmeronProgressQuicklyFinding2020 compared proteins alignment tools to find faster alternatives, without a lose in precision, showing that DIAMOND [@buchfinkSensitiveProteinAlignments2021], when switched to sensitive parameters instead of defaults, correctly found 87% of the reciprocal best hits of BLASTP [@camachoBLASTArchitectureApplications2009] in less than 8% of the time.
Recently, @holzerPOCPnfAutomaticNextflow2024 suggested the use of DIAMOND with ultra-sensitive settings to compute POCP faster than with BLASTP. His approach is based on previously available script [@holzerHoelzerPocp2020], implemented as a nextflow workflow [@holzerPOCPnfAutomaticNextflow2024]. However, his comparisons are based on limited set of 5 genera, each ranging from 15 to 167 genomes. 
However, the the current implementations of POCP available as tools assume conserved proteins have unique matches [@holzerHoelzerPocp2020; @holzerPOCPnfAutomaticNextflow2024;@riescoUpdateProposedMinimal2024;@linSilentGeneBiopyBiopy2021], differing from the original implementation of POCP which had no such limitation [@qinProposedGenusBoundary2014].
We need a clear definition of POCP to clarify the process and ensure repeatability.


To achieve this, we aimed to identify a scalable alternative to BLASTP to compute POCP. Whilst fast and scalable, this alternative should not compromise the accuracy of the original approach.
Second, as POCP provides an interpretable and used metric that can delineate bacterial genera, we will evaluate the ability of POCP to correctly delineate bacterial genera using the optimised implementation.
Based on these findings, we hope to provide microbiologists with a best-practice tool they can confidently use in their workflow to determine the genus assignment of a genome.

::: {#suppfig-lpsn}

```{r suppfiglpsn}
knitr::include_graphics(tar_read(fig_lpsn_stats_png))
```

Cumulative number of validly published genera names according to the International Code of Nomenclature of Prokaryotes (ICNP). The year 2014 is highlighted as it corresponds to the year of publication of the paper by Qin et al. (doi: 10.1128/JB.01688-14) describing the Percentage of Conserved Proteins (POCP) to delineate genus. The number of valid genera is highlighted ten years later. The data was accessed on 2024-07-19 at the List of Prokaryotic names with Standing in Nomenclature.
:::



# Methods

## Standardisation of protein sequences and taxonomy via GTDB

The Genome Taxonomy DataBase (GTDB) provides curated taxonomy along with genomes and genome-derived proteins sequences [@parksGTDBOngoingCensus2022].
We devised a set of inclusion criteria to facilitate inclusion of a diverse range of taxonomic groups, while maintaining achievable comparisons with the time, human and computing resources available.

The criteria for study of a bacterial entry within the GTDB (r214) was: (1) the bacteria has a valid name according to the LPSN, (2) the entry is a representative genome, (3) the bacteria belongs to a family with at least two genera, and (5) it belongs to a genus with at least ten genomes. Based on these criteria, the protein sequence files for the shortlisted bacteria were obtained from GTDB.

The bacterial phylogenetic tree of the shortlisted genomes was constructed by trimming the bacterial tree released by GTDB using custom Python scripts and the ETE3 library [@huerta-cepasETEReconstructionAnalysis2016].



## Definition of Percentage of Conserved Proteins (POCP)

The percentage of conserved proteins (POCP) between two genomes $Q$ and $S$ is defined as:

$$
POCP = \dfrac{C_{QS} + C_{SQ}}{T_Q + T_S} \times 100\%
$$ {#eq-pocp}

where $C_{QS}$ represent the conserved number of proteins from $Q$ when aligned to $S$ and conversely $C_{SQ}$ represent the conserved number of proteins from $S$ when aligned to $Q$, and $T_Q + T_S$ represent the total number of proteins in the two genomes being compared, respectively [adapted from @qinProposedGenusBoundary2014].
The range of POCP is theoretically $\left[0;100\%\right]$.
Conserved proteins are defined as protein sequences matches from the query with an e-value < $10^{âˆ’5}$, a sequence identity > 40%, and an aligned region > 50% of the query protein sequence length.

Pairwise comparisons between a query sequence ($Q$) and a subject sequence ($S$) were defined by banning self-comparisons ($Q \neq S$) and considering reciprocal comparisons ($Q\text{-}S$ and $S\text{-}Q$) only within the same family to prevent exponential explosion.

However, proteins sequences from the query can match multiple subject sequences in the case of duplicated genes.
While briefly mentioned in the original paper that "The number of conserved proteins in each genome of strains being compared was slightly different because of the existence of duplicate genes (paralogs)" [@qinProposedGenusBoundary2014, p. 2211], the expected influence on the POCP values is lacking.
In our experience, this results in POCP values above the theoretical upper bound of 100%.
Therefore, we defined the POCP with unique matches (POCPu) between two genomes $Q$ and $S$ as:

$$
POCPu = \dfrac{C_{uQS} + C_{uSQ}}{T_Q + T_S} \times 100\%
$$ {#eq-pocpu}

where $C_{uQS}$ represent the conserved number of proteins from *the unique matches of* $Q$ when aligned to $S$ and conversely $C_{uSQ}$ represent the conserved number of proteins from *the unique matches of* $S$ when aligned to $Q$, and $T_Q + T_S$ represent the total number of proteins in the two genomes being compared, respectively.
Thus the range of POCP is actually $\left[0;\infty\right[$ and the range of POCPu is $\left[0;100\%\right]$.
Note that the assumption regarding unique matches is made implicitly when using some POCP implementation [e.g., @holzerHoelzerPocp2020; @holzerPOCPnfAutomaticNextflow2024; @linSilentGeneBiopyBiopy2021].

## Approaches for proteins sequence alignment benchmark

In @qinProposedGenusBoundary2014, guidance was provided on how to implement the computation of POCP, including the use of BLASTP, as implemented in Protologger [@hitchAutomatedAnalysisGenomic2021].
As our 'standard' POCP implementation, we used BLASTP v2.14.0+ [@camachoBLASTArchitectureApplications2009] with parameters from @qinProposedGenusBoundary2014 (@tbl-tools-parameters).
We also considered a modified implementation of the BLASTP approach, named BLASTPDB where BLAST databases are first built for the two genomes considered (@tbl-tools-parameters).
This allow parallel alignments on multiple CPU, which is not possible with BLASTP.
We then included two tools that were designed as faster local-protein-alignment approaches and used as alternatives to BLASTP: DIAMOND v2.1.6 [@buchfinkSensitiveProteinAlignments2021] and MMseqs2 v15.6f452 [@steineggerMMseqs2EnablesSensitive2017].
The former is used in @holzerPOCPnfAutomaticNextflow2024 while the latter is used in EzAAI [@kimIntroducingEzAAIPipeline2021].
Similarly to BLASTPDB, these approaches require that a protein database is built for each genome before performing the alignment (@tbl-tools-parameters).
DIAMOND and MMseqs2 were both used with four different sensitivity thresholds (@tbl-tools-parameters) based on a recent comparisons [@buchfinkSensitiveProteinAlignments2021].

```{r tbl-tools-parameters}
#| tbl-cap: "List of the ten approaches and associated parameters for the many-versus-many proteins alignments tools used in the benchmark. The recommended approach is indicated in bold."
tibble::tribble(
  ~Name, ~Parameters,
  "BLAST_BLASTP","--evalue 0.00001 --qcov_hsp_perc 50.0",
  "BLAST_BLASTPDB","--evalue 0.00001 --qcov_hsp_perc 50.0",
  "DIAMOND_FAST","--evalue 0.00001 --query-cover 50.0 --fast",
  "DIAMOND_SENSITIVE","--evalue 0.00001 --query-cover 50.0 --sensitive",
  "DIAMOND_VERYSENSITIVE","--evalue 0.00001 --query-cover 50.0 --very-sensitive",
  "DIAMOND_ULTRASENSITIVE","--evalue 0.00001 --query-cover 50.0 --ultra-sensitive",
  "MMSEQS2_S1DOT0","--e-profile 0.00001 --cov-mode 1 -c 0.50 -s 1.0",
  "MMSEQS2_S2DOT5","--e-profile 0.00001 --cov-mode 1 -c 0.50 -s 2.5",
  "MMSEQS2_S6DOT0","--e-profile 0.00001 --cov-mode 1 -c 0.50 -s 6.0",
  "MMSEQS2_S7DOT5","--e-profile 0.00001 --cov-mode 1 -c 0.50 -s 7.5"
) %>% 
  mutate(
    Name = if_else(Name=="DIAMOND_VERYSENSITIVE", "**DIAMOND_VERYSENSITIVE**", Name),
    `Database creation` = if_else(Name == "BLAST_BLASTP", "No", "Yes"),
    Parameters = glue::glue("`{p}`", p=Parameters)
    ) %>%
  rename("Approach name"="Name") %>% 
  select(`Approach name`, `Database creation`, Parameters) %>% knitr::kable()
```

All proteins matches were filtered to only keep matches with > 40 % identity to all the query sequences matches for POCP ($C_{QS}$ and $C_{SQ}$ in @eq-pocp) and only unique query sequence matches for POCPu ($C_{QS}$ and $C_{SQ}$ in @eq-pocpu).
Note that the filtering was adapted to the method as the range of percentage of identity in MMseqs2 is $[0-1]$ and $[0-100]$ for BLAST and DIAMOND.
The total number of proteins per genomes ($T_Q$ and $T_S$ in @eq-pocp and @eq-pocpu) was computed using seqkit stats v2.2.0 [@shenSeqKitCrossPlatformUltrafast2016].

Linear regressions were implemented using `r R.version.string` to fit the expected POCP (or POCPu) values obtained via the legacy BLAST_BLASTP approach against the others approaches considered.
The coefficient of determination R^2^ of the linear regression is used as an interpretable and bounded goodness-of-fit measure between the expected and measured values instead of others errors measurement [@chiccoCoefficientDeterminationRsquared2021].
We did not rely on the adjusted coefficient of determination as the linear regressions had only one predictor, namely the POCP (or POCPu) values of the evaluated approach.


## Metrics to evaluate genus delineation

We computed classification metrics with a positive event defined as "both genomes belong to the same genus".
Thus, for a pair of bacterial genomes with a POCP (or POCPu) > 50%, the pair is a True Positive ($TP$) if the pair belong to the same genus, or if not to False Positive ($FP$).
Conversely, for a pair of bacterial genomes with a POCP (or POCPu) $\leq$ 50%, the pair is a False Negative ($FN$) if the pair belong to the same genus, or if not to True Negative ($TN$).
We assess the classification performance of both POCP and POCPu with the Matthews Correlation Coefficient (MCC; @eq-mcc).

$$
MCC = \dfrac{TP \times TN - FP \times FN}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN+FN)}}
$$ {#eq-mcc}

The coefficient has a range of $\left[-1;+1\right]$ and is only high in case of perfect classification, as a MCC of 0 indicates a random classification. Plus, the MCC compensates for unequal class sizes compared to others metrics such as accuracy or F1-score [@chiccoAdvantagesMatthewsCorrelation2020].

## Workflow implementation

Automatic protein sequences download, data preprocessing, many-versus-many protein alignments, as well as POCP computation and delineation metrics calculations were within a nextflow v23.10.0 [@ditommasoNextflowEnablesReproducible2017] workflow, using components of nf-core [@ewelsNfcoreFrameworkCommunitycurated2020].
Tools used are provided within Docker container [@merkelDockerLightweightLinux2014] or bioconda [@thebiocondateamBiocondaSustainableComprehensive2018] environments to ensure reproducibility, scalability and ease future extensions of the benchmark.

Nextflow natively keep track of the time, CPU, memory and disk usage of each process in an execution trace log file that we used to evaluate computing resources utilization. Process duration is available as walltime and realtime, the CPU usage is reported as a percentage of usage of a unique CPU, meaning multi-threaded processes will have a value higher than 100%.

Statistical analyses and visualisation were conducted within R using targets v.1.7.0 [@landauTargetsPackageDynamic2021].


# Results

We evaluated the use of ten proteins alignment approaches based on three tools for calculation of the Percentage Of Conserved Proteins (POCP). For this, genomes from the GTDB were used [@parksGTDBOngoingCensus2022].


```{r funnel}
funnel <- c(
  "GTDB_Genomes" = 394932,
  "Representatives" = 80789,
  "Valid_names" = 11699,
  "More_10_species_per_genus" = 5904,
  "More_1_genus_per_family" = 4767
)
funnel_text <- funnel %>% prettyNum(big.mark=" ") %>% as.list() %>% 
  glue::glue_data(
    "Out of a total of {GTDB_Genomes} GTDB bacterial genomes",
    "{Representatives} are representative genomes",
    "{Valid_names} have valid names",
    "{More_10_species_per_genus} belongs to a genus with at least ten genomes",
    "and {More_1_genus_per_family} belongs to a family with at least two genera", .sep = ", "
    )
phyla_count_text <- tar_read(tree_metadata) %>%
  select(Phylum:Species) %>%
  group_by(Phylum) %>%
  summarise(across(everything(),n_distinct)) %>%
  arrange(desc(Species)) %>%
  glue::glue_data(
    "{Phylum} ({Family} families, {Genus} genera, {Species} species)",
    Species = prettyNum(Species, big.mark=" ")) %>%
  glue::glue_collapse(sep = ", ", last = " and ")
```


```{r cpu_hours}
stats_by_type <- tar_read(family_metadata) %>%
  select(Family,benchmark_type, n_genomes,CPU_hours) %>%
  group_by(benchmark_type) %>% 
  mutate(
    n_comparisons_planned=n_genomes*(n_genomes-1),
    n_comparisons_realized=if_else(benchmark_type=="full",
                          n_comparisons_planned*10, n_comparisons_planned)
                          ) %>%
  summarise(
    n_families = n(),
    n_genomes = sum(n_genomes),
    n_planned = sum(n_comparisons_planned*10),
    n_realized = sum(n_comparisons_realized),
    total_hours = sum(CPU_hours)
    )
overall_stats <- stats_by_type %>% 
  summarise(across(!benchmark_type,sum)) %>% 
  mutate(
    total_hours = round(total_hours),
    total_years = as.period(total_hours, unit = "hours") %>% as.numeric("years")
  ) %>% mutate(across(everything(), ~prettyNum(.x,big.mark = " ", digits=2)))
stats_by_type_text <- stats_by_type %>%
  mutate(across(everything(), ~prettyNum(.x,big.mark = " ", digits=2))) %>% 
  glue::glue_data(
    "({n_families} families, {n_genomes} genomes, {n_realized} comparisons)"
    )
```


`r funnel_text`.
This shortlist of `r overall_stats$n_genomes` genomes covers a wide range of bacterial phylogenetic diversity across four phyla: `r phyla_count_text`.

The families were split into two benchmark group: the full benchmark using all ten approaches `r stats_by_type_text[1]`, or using only the recommended approach `r stats_by_type_text[2]`. 

In total, this study conducted `r overall_stats$n_realized` pairwise comparisons with a total of `r overall_stats$total_hours` CPU-Hours (`r overall_stats$total_years` in years).

::: {#fig-tree-phyla}

```{r tree-phyla}
n_genomes <- nrow(tar_read(genome_metadata)) %>% prettyNum(big.mark=" ")
knitr::include_graphics(tar_read(fig_tree_phyla_count_png))
```

Overview of the phylogenetic diversity of the genomes shortlisted for the benchmark. The `r n_genomes` genomes are placed on the phylogenetic tree of the GTDB (A) and colored depending whether the genomes were included in the benchmark with all approaches (shamrock green) or only with the recommended approach (sky magenta). The distribution of genomes by Phyla is indicated for each benchmark type (B).
:::



## Comparison with the BLAST_BLASTP legacy approach

```{r genomes-in-full}
n_genomes_in_full <- stats_by_type %>% 
  filter(benchmark_type=="full") %>% pull(n_genomes) %>% 
  prettyNum(big.mark = " ")
```


Using the `r n_genomes_in_full` genomes from the full benchmark (@fig-tree-phyla), we evaluate whether the accuracy of the POCP calculation is not sacrificed in the name of computational performance.

We first made sure that the database approach to BLAST_BLASTP (@tbl-tools-parameters), that allows for parallel computations produced similar POCP values to the BLAST_BLASTP approach (@suppfig-blastdb A).

::: {#suppfig-blastdb}
```{r blastdb}
n_blastdb_comparisons <- tar_read(blast_vs_all_pocpu) %>%
  count(tool) %>% pull(n) %>%
  unique() %>% prettyNum(big.mark=" ")
knitr::include_graphics(tar_read(fig_blast_vs_blastdb_png))
```

Adequacy between POCP (A) and POCPu (B) values computed with the legacy BLAST_BLASTP against the BLAST_BLASTPDB approach that build databases before alignment.
Each point ($n$ = `r n_blastdb_comparisons` per tool) represents a POCP/POCPu value between two genomes (see @eq-pocp and @eq-pocpu).
The colors represent the probability of finding a point within a certain region, with darker colors indicating higher probabilities. The regions shown are the smallest areas that contain 50%, 80%, 95%, 99% and 100% of the data points, and are known as Highest Density Regions (HDRs).
Coefficient of determination ($R^2$) and associated $p$-value are shown on top of each linear regressions.
:::



::: {#tbl-R2}

```{r R2}
#| classes: plain
library(gt)
tar_load(R2_table)
n_comparisons_in_lm <- unique(R2_table$POCP_nobs) %>% prettyNum(big.mark = " ")
R2_table %>% arrange(desc(POCPu_R2)) %>%
    gt::gt(rowname_col = "tool") %>%
    tab_stubhead("Approach name") %>% cols_align(align = "left", columns = "tool") %>%
    tab_spanner("POCP", starts_with("POCP_")) %>%
    tab_spanner("POCPu", starts_with("POCPu_")) %>% cols_hide(ends_with("_nobs")) %>%
    cols_label(
      POCP_R2 = md("$R^2$"),POCPu_R2 = md("$R^2$"),
      POCP_p_label = md("$p$-value"),POCPu_p_label = md("$p$-value")
    ) %>%
  tab_options(column_labels.font.weight = "bold")
```

Coefficient of determination ($R^2$) and associated $p$-value for linear regressions matching the POCP and POCPu values computed by each approach against the respective POCP and POCPu values of BLAST_BLASTP legacy approach. Each linear regression are based on $n$ = `r n_comparisons_in_lm` comparisons per approach. Approaches are sorted by decreasing POCPu $R^2$ values.
:::


All flavors of DIAMOND have a coefficient of determination ($R^2$) above 0.99 when matching their POCP values with the original from BLAST_BLASTP, with the exception of the DIAMOND_FAST approach that deviates more from the expected values (@fig-blast-vs-all-pocp and @tbl-R2).
This deviation is exacerbated when using the MMSEQS2_S1DOT0 approach, but is somehow rescued with the others MMSEQS2 approaches, though they perform worse than the DIAMOND approaches.
It should be noted that the reported POCP values exceed the supposed POCP upper bound of 100% (@fig-blast-vs-all-pocp).


::: {#fig-blast-vs-all-pocp}

```{r blast_vs_all_pocp}
n_blast_comparisons <- tar_read(blast_vs_all_pocp) %>%
  count(tool) %>% pull(n) %>%
  unique() %>% prettyNum(big.mark=" ")
knitr::include_graphics(tar_read(fig_blast_vs_all_pocp_png))
```

Adequacy between POCP values computed with the legacy BLAST_BLASTP against flavors of faster alternatives: DIAMOND [@buchfinkSensitiveProteinAlignments2021] and MMSEQS2 [@steineggerMMseqs2EnablesSensitive2017].
Each point ($n$ = `r n_blast_comparisons` per tool) represents a POCP value between two genomes (see @eq-pocp).
The colors represent the probability of finding a point within a certain region, with darker colors indicating higher probabilities. The regions shown are the smallest areas that contain 50%, 80%, 95%, 99% and 100% of the data points, and are known as Highest Density Regions (HDRs).
Coefficient of determination ($R^2$) and associated $p$-value are shown on top of each linear regressions.
:::


::: {#fig-blast-vs-all-pocpu}

```{r blast_vs_all_pocpu}
n_blast_comparisons_pocpu <- tar_read(blast_vs_all_pocpu) %>%
  count(tool) %>% pull(n) %>%
  unique() %>% prettyNum(big.mark=" ")
knitr::include_graphics(tar_read(fig_blast_vs_all_pocpu_png))
```

Adequacy between POCPu values computed with the legacy BLAST_BLASTP against flavors of faster alternatives: DIAMOND [@buchfinkSensitiveProteinAlignments2021] and MMSEQS2 [@steineggerMMseqs2EnablesSensitive2017].
Each point ($n$ = `r n_blast_comparisons_pocpu` per tool) represents a POCPu value between two genomes (see @eq-pocpu).
The colors represent the probability of finding a point within a certain region, with darker colors indicating higher probabilities. The regions shown are the smallest areas that contain 50%, 80%, 95%, 99% and 100% of the data points, and are known as Highest Density Regions (HDRs).
Coefficient of determination ($R^2$) and associated $p$-value are shown on top of each linear regressions.
:::


These higher-than-100% POCP values disappears when using the POCPu (@fig-blast-vs-all-pocpu and @suppfig-blastdb B).
Otherwise, the same patterns observed for POCP hold for POCPu, though with higher values of coefficient of determination (@fig-blast-vs-all-pocpu and @tbl-R2).
The 3 different sensitive approaches of DIAMOND produce POCPu values that match perfectly the ones produce by the legacy approach BLAST_BLASTP.
However, the MMSEQS2 approaches, whilst better with POCPu than POCP, still tend to underestimate POCPu values.
For all tools, two clusters of yellow points are visible (@fig-blast-vs-all-pocpu). They indicate regions where at least 50% of the data points are located, with the first and second regions being below and above 50% on the x-axis BLAST_BLASTP POCPu, respectively. 

::: {#tbl-tools-metrics}

```{r tools-metrics}
n_processes <- tar_read(tool_table) %>% pull(n) %>% unique() %>% prettyNum(big.mark=" ")
tar_read(tool_table) %>% filter(tool!="BLAST_BLASTP") %>%
  select(-n) %>%
  rename("Approach name" = "tool",
         "Time"="time_fold", "Memory"="memory_fold",
         "CPU"="cpu_fold", "Disk usage (I/O)"="io_fold") %>% 
  knitr::kable(digits = 3)
```

Fold change of computing metrics for the 9 approaches used in the benchmark compared to the BLAST_BLASTP approach.
The metrics include processing time as real-time, memory usage, CPU usage and disk usage as input/output (I/O).
A fold change below 1 means the metric is lower, whilst above 1 means it is higher, compared to the BLAST_BLASTP approach.
The fold change values are median computed over $n$ = `r n_processes` number of processes tracked per approach.
:::

The BLAST_BLASTPDB approach is a strong contender for a BLAST_BLASTP alternative because whilst using more resources, it performs exactly the same as BLAST_BLASTP (@suppfig-blastdb and @tbl-R2) in a fraction of the time (@tbl-tools-metrics).
Still, DIAMOND-based sensitive approaches are way faster with excellent adequacy with BLAST_BLASTP approach, especially for POCPu (@tbl-R2).
Whilst DIAMOND_ULTRASENSITIVE would have the highest $R^2$ value using POCPu (@tbl-R2), it has the highest memory consumption and disk usage of the tested approaches (@tbl-tools-metrics).
A more sustainable alternative would be DIAMOND_VERYSENSITIVE that performs 10 times faster than BLAST_BLASTPDB, in less than $1/20^{th}$ of the time of BLAST_BLASTP, while still maintaining reasonable usage of the resources (@tbl-tools-metrics).
More importantly, DIAMOND_VERYSENSITIVE POCPu provides extremely similar results to the legacy approach BLAST_BLASTP (@fig-blast-vs-all-pocpu and @tbl-R2) and is essentially identical to DIAMOND_ULTRASENSITIVE POCPu $R^2$ up to 5 digits (@tbl-R2).
Therefore, we consider DIAMOND_VERYSENSITIVE to be a valid and scalable alternative to BLAST_BLASTP for POCP/POCPu computations.

## Genus delineation with POCP and POCPu

```{r confusion_matrix}
targets::tar_load(c(pocp_confusion,pocpu_confusion))
```

Then, we put to the test the 50%-threshold of POCP and POCPu, and evaluate how useful these metrics are to delineate bacterial genera.
We use all the `r n_genomes` genomes (@fig-tree-phyla) and calculate POCP and POCPu with the DIAMOND_VERYSENSITIVE approach (@fig-genus-delineation).
Optimistically, we expected two bell-shaped distributions, with the "Between genera" POCPs neatly apart from the "Within genus" POCPs by a gap around 50%.

The two distributions do overlap though (@fig-genus-delineation A).
Indeed, POCP yields a high number of false positives (FP = `r pocp_confusion["FP"]`), where the "Between genera" distribution is above 50%, especially compared to the number of true negatives (TN = `r pocp_confusion["TN"]`), where the "Between genera" distribution is below 50%.
Thankfully, most of the "Within genus" distribution of POCP is above 50% (TP = `r pocp_confusion["TP"]`), with fewer below the threshold (FN = `r pocp_confusion["FN"]`).

POCPu is closer to our expectations (@fig-genus-delineation B).
"Between genera" POCPu follows a bimodal distribution, with the highest peak and most of the distribution below the 50% threshold (TN = `r pocpu_confusion["TN"]`).
Still, this distribution spills above the threshold, indicating POCPu also produces false positives (FP = `r pocp_confusion["FP"]`).
Like POCP, "Within genus" POCPu concentrate largely above the threshold of 50% (TP = `r pocpu_confusion["TP"]`), with fewer below the threshold (FN = `r pocpu_confusion["FN"]`).


::: {#fig-genus-delineation}

```{r genus-delineation}
#| fig-width: 11
#| fig-height: 6
#| fig-dpi: 300
tar_load(pocpu_group_sizes)
knitr::include_graphics(tar_read(p_genus_delineation_png))
```

A data-driven evaluation of how well POCP and POCPu distinguish genera.
Distribution of POCP (A) and POCPu (B) values for all pairwise genome comparisons: `r pocpu_group_sizes[1]` in orange and `r pocpu_group_sizes[2]` in sky blue, both based on GTDB taxonomy.
Contrast these true categories with POCP/POCPu decisions: POCP > 50%, meaning right of the dashed line (A, B) indicates more than half of shared conserved proteins, and hence same genus.
POCP and POCPu values are calculated with the recommended approach DIAMOND_VERYSENSITIVE (@tbl-tools-parameters).
How well POCPu delineates genera is tested with the Matthews Correlation Coefficient [MCC, @chiccoAdvantagesMatthewsCorrelation2020]. We show MCC values for each family where MCC of -1 and +1 indicates perfect misclassification and classification, respectively (C). Random genus delineation would give MCC = 0. The dashed line indicated the overall MCC when not splitting by family. We also highlight how many n genomes are included per family, and their phyla in the vertical facets (C).
:::

```{r mcc}
mcc_pocp <- targets::tar_read(mcc_pocp_global) %>%
  pull(mcc) %>% prettyNum(digits = 2)
mcc_pocpu <- targets::tar_read(mcc_pocpu_global) %>%
  pull(mcc) %>% prettyNum(digits = 2)
tally_mcc_thresholds <- summarise(
  tar_read(mcc_pocpu_family), 
  total = n(), n_70 = sum(mcc >= 0.7), n_25 = sum(mcc <= 0.25)
)
```

We quantify our findings on the confusion matrix using the  Matthews Correlation Coefficient (@eq-mcc).
MCC is a binary classification rate that gives a high score only when the classifier correctly predicts the majority of positive and negative cases.
Therefore, POCPu (MCC = `r mcc_pocpu`) surpasses POCP (MCC = `r mcc_pocp`) to delineate bacterial genus.

When we consider the bacterial families separately, another pattern emerge (@fig-genus-delineation C).
In `r tally_mcc_thresholds["n_25"]` families out of 35, POCPu is clearly not adequate to delineate genus with low MCC (MCC $\leq$ 0.25; @fig-genus-delineation C).
The large family of _Streptomycetaceae_ (Actinomycetota), for instance, exhibits many `r targets::tar_read(streptomycetaceae)`.
Not all is lost, as `r tally_mcc_thresholds["n_70"]` families out of 35 show that POCPu delineates bacterial genera accurately (MCC $\geq$ 0.7;  @fig-genus-delineation C). For instance, for all the comparisons done within the _Lactobacillaceae_ family (Bacillota), we see `r targets::tar_read(lactobacillaceae)`.
All categories of the confusion matrix vary greatly, which underline the need to a metric that can aggregate these counts without bias, and thus show that while POCPu is not a one-size-fits-all method, it can correctly delineate genera.

We even leverage our large dataset to assess claims that POCP is influenced by differences in genome size [@riescoUpdateProposedMinimal2024].
We found no convincing patterns to support the claim in difference of genome size (@suppfig-delta A) nor in number of proteins (i.e., proteome; @suppfig-delta B).
Overall, POCPu provides a useful and interpretable metric to delineate genera.

::: {#suppfig-delta}

```{r suppfigdelta}
knitr::include_graphics(tar_read(fig_delta_proteome_genome_png))
```

Absence of relationship between POCPu and differences in genome size (A) and proteome size (B). Each point represents a comparison between two GTDB genomes for which the absolute genome size were compared (A) and the total number of proteins (B).
The colors represent the probability of finding a point within a certain region, with darker colors indicating higher probabilities. The regions shown are the smallest areas that contain 50%, 80%, 95%, 99% and 100% of the data points, and are known as Highest Density Regions (HDRs).
:::


# References

::: {#refs}
:::
